{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion Videos\n",
        "\n",
        "This notebook allows you to generate videos by interpolating the latent space of [Stable Diffusion](https://github.com/CompVis/stable-diffusion).\n",
        "\n",
        "You can either dream up different versions of the same prompt, or morph between different text prompts (with seeds set for each for reproducibility).\n",
        "\n",
        "If you like this notebook:\n",
        "- consider giving the [repo a star](https://github.com/nateraw/stable-diffusion-videos) ‚≠êÔ∏è\n",
        "- consider following me on Github [@nateraw](https://github.com/nateraw) \n",
        "\n",
        "You can file any issues/feature requests [here](https://github.com/nateraw/stable-diffusion-videos/issues)\n",
        "\n",
        "Enjoy ü§ó"
      ],
      "metadata": {
        "id": "z4GhhH25OdYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "dvdCBpWWOhW-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwfc0ej1L9A0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install stable_diffusion_videos[realesrgan]\n",
        "! git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate with Hugging Face Hub\n",
        "\n",
        "You have to be a registered user in ü§ó Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ],
      "metadata": {
        "id": "dR5iVGYbOky5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "GmejIGhFMTXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the App üöÄ"
      ],
      "metadata": {
        "id": "H7UOKJhVOonb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Interface\n",
        "\n",
        "This step will take a couple minutes the first time you run it."
      ],
      "metadata": {
        "id": "g71hslP8OntM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_diffusion_videos import interface"
      ],
      "metadata": {
        "id": "bgSNS368L-DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Connect to Google Drive to Save Outputs\n",
        "\n",
        "#@markdown If you want to connect Google Drive, click the checkbox below and run this cell. You'll be prompted to authenticate.\n",
        "\n",
        "#@markdown If you just want to save your outputs in this Colab session, don't worry about this cell\n",
        "\n",
        "connect_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Then, in the interface, use this path as the `output` in the Video tab to save your videos to Google Drive:\n",
        "\n",
        "#@markdown > /content/gdrive/MyDrive/stable_diffusion_videos\n",
        "\n",
        "\n",
        "if connect_google_drive:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "kidtsR3c2P9Z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Launch\n",
        "\n",
        "This cell launches a Gradio Interface. Here's how I suggest you use it:\n",
        "\n",
        "1. Use the \"Images\" tab to generate images you like.\n",
        "    - Find two images you want to morph between\n",
        "    - These images should use the same settings (guidance scale, height, width)\n",
        "    - Keep track of the seeds/settings you used so you can reproduce them\n",
        "\n",
        "2. Generate videos using the \"Videos\" tab\n",
        "    - Using the images you found from the step above, provide the prompts/seeds you recorded\n",
        "    - Set the `num_walk_steps` - for testing you can use a small number like 3 or 5, but to get great results you'll want to use something larger (60-200 steps). \n",
        "\n",
        "üí° **Pro tip** - Click the link that looks like `https://<id-number>.gradio.app` below , and you'll be able to view it in full screen."
      ],
      "metadata": {
        "id": "VxjRVNnMOtgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "id": "8es3_onUOL3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "mFCoTvlnPi4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use `walk` programatically\n",
        "\n",
        "The other option is to not use the interface, and instead use `walk` programatically. Here's how you would do that..."
      ],
      "metadata": {
        "id": "SjTQLCiLOWeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we define a helper fn for visualizing videos in colab"
      ],
      "metadata": {
        "id": "fGQPClGwOR9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def visualize_video_colab(video_path):\n",
        "    mp4 = open(video_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(\"\"\"\n",
        "    <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url)"
      ],
      "metadata": {
        "id": "GqTWc8ZhNeLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Walk! üö∂‚Äç‚ôÄÔ∏è"
      ],
      "metadata": {
        "id": "Vd_RzwkoPM7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_diffusion_videos import walk\n",
        "\n",
        "video_path = walk(['a cat', 'a dog'], [42, 1337], num_interpolation_steps=3, make_video=True)\n",
        "visualize_video_colab(video_path)"
      ],
      "metadata": {
        "id": "Hv2wBZXXMQ-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}